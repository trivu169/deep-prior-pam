{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Image Prior (DIP) for PAM - Batch Mode Only\n",
    "## Tri Vu - Updated 051620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from define_model import *\n",
    "from build_unet import *\n",
    "from utils import *\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from numba import cuda\n",
    "from keras.models import load_model\n",
    "import scipy.io as sio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Choose which gpu to run the training \"\"\"\n",
    "gpu = 0  # 0 for first gpu, 1 for 2nd gpu\n",
    "if gpu == 0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "elif gpu == 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Mode Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_MODE = True  # Run DIP on a set of data for evaluation\n",
    "SSIM_ITER = True  # Run DIP on randomly chosen 3 samples to test ssim vs iterations\n",
    "WHOLEIMG_MODE = False   # Run DIP on the whole image with 300x300 subimgs\n",
    "\n",
    "SAVE_MODEL = True  # Save trained model and input noise\n",
    "SAVE_LOSS = True\n",
    "SAVE_OUTPUT = True  # Save auxillary info (training time and noise reg) output image, \n",
    "                    # with corrected image in the 2nd channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Params Input and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  7  8 10 11 12 14 15 16 17 18 19 20 21 22 24 25 26 27 28\n",
      " 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "if BATCH_MODE:\n",
    "    imgpath = './Data/10_5/'\n",
    "    start_count = 1\n",
    "    batch_end = 50\n",
    "    batch_range = list(np.arange(start_count, batch_end))\n",
    "    if SSIM_ITER:\n",
    "#         batch_range = random.sample(list(batch_range),6)\n",
    "        random_batch_range = [6, 45, 23, 32, 9, 13]\n",
    "        for i in random_batch_range:\n",
    "            batch_range.remove(i)\n",
    "        batch_range = np.asarray(batch_range)\n",
    "        print(batch_range)\n",
    "    list_dir = os.listdir(imgpath)\n",
    "    list_file = [f for f in list_dir if isfile(join(imgpath, f))]\n",
    "    prefix, suffix = list_file[0].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if WHOLEIMG_MODE:\n",
    "#     IMG_SIZE = 260\n",
    "#     imgpath = './Data/'\n",
    "#     imgname = 'brain_xiaoyi_12_6'\n",
    "#     imgsuffix = 'png'\n",
    "#     im_all = cv2.imread(imgpath + imgname + '.' + imgsuffix)\n",
    "#     print(im_all.shape)\n",
    "\n",
    "#     if im_all.shape[0] % IMG_SIZE != 0:\n",
    "#         num_x = im_all.shape[0]//IMG_SIZE\n",
    "#         dim_x = (num_x+1)*IMG_SIZE\n",
    "#     else:\n",
    "#         num_x = im_all.shape[0]//IMG_SIZE\n",
    "#         dim_x = im_all.shape[0]\n",
    "#     if im_all.shape[1] % IMG_SIZE != 0:\n",
    "#         num_y = im_all.shape[1]//IMG_SIZE\n",
    "#         dim_y = (num_y+1)*IMG_SIZE\n",
    "#     else:\n",
    "#         num_y = im_all.shape[1]//IMG_SIZE\n",
    "#         dim_y = im_all.shape[1]\n",
    "\n",
    "#     im_all_zero = np.zeros((dim_x, dim_y, im_all.shape[2]), dtype=np.uint8)\n",
    "#     im_all_zero[:im_all.shape[0], :im_all.shape[1], :] = im_all\n",
    "# #     im_all = im_all[:dim_x, :dim_y, :]\n",
    "#     im_all = np.copy(im_all_zero)\n",
    "#     im_out = np.zeros((im_all.shape[0], im_all.shape[1]))\n",
    "#     im_down_out = np.copy(im_out)\n",
    "#     im_all = np.pad(im_all, ((20, 20), (20, 20), (0,0)), 'constant')  # zero pad 20x20 along axis 0 and 1\n",
    "    \n",
    "# #     fig = plt.figure(figsize=(100, 100))\n",
    "# #     plt.imshow(im_all[:, :, 1])\n",
    "# #     plt.show()\n",
    "\n",
    "#     lin_x = np.arange(150, im_all.shape[1], 260)\n",
    "#     lin_y = np.arange(150, im_all.shape[0], 260)\n",
    "#     total_count = len(lin_x)*len(lin_y)\n",
    "#     print(total_count)\n",
    "    \n",
    "#     count = 1\n",
    "#     for i in lin_x:\n",
    "#         for j in lin_y:\n",
    "#             print(count)\n",
    "#             im_temp = im_all[j-150:j+150, i-150:i+150, :]\n",
    "#             im, im_gt, im_masked, im_mask, im_down, factor, _, _ = readImg(im_temp)\n",
    "#             if count == 1:\n",
    "#                 show_output = True\n",
    "#             else:\n",
    "#                 show_output = False\n",
    "#             [sr_image, l, model, \n",
    "#              totalTrainingTimeHr, \n",
    "#              input_noise] = train_dp(im_masked, im_gt, im_mask, iter=5000, \n",
    "#                      noise_reg=0.07, show_output=show_output)\n",
    "#             tmp = np.squeeze(sr_image)\n",
    "#             im_out[j-150:j+110, i-150:i+110] = tmp[20:280, 20:280]\n",
    "#             im_down_out[j-150:j+110, i-150:i+110] = im_down[20:280, 20:280]\n",
    "#             count += 1\n",
    "            \n",
    "#             if SAVE_OUTPUT:\n",
    "#                 model.save(imgpath + '/output_brain_xiaoyi/' + imgname + str(i) + str(j) + '.h5')\n",
    "#                 inputNoise = np.squeeze(input_noise)\n",
    "#                 inputNoise = inputNoise.reshape((inputNoise.shape[0], inputNoise.shape[1]*inputNoise.shape[2]))\n",
    "#                 np.savetxt(imgpath + '/output_brain_xiaoyi/' + imgname + '_inputNoise' + str(i) + str(j) + '.txt', \n",
    "#                            np.asarray(np.squeeze(inputNoise)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if WHOLEIMG_MODE:\n",
    "    imgpath = './Data/brain_map_all_patterns/4_1/'\n",
    "#     imgname = 'brain_xiaoyi_12_6'\n",
    "    imgname = 'brain_map_4_1'\n",
    "    if imgname == 'brain_xiaoyi_12_6':\n",
    "        TRUE_SIZE = 1000\n",
    "        PAD_SIZE = 70  # Each size\n",
    "    else:\n",
    "        TRUE_SIZE = 300\n",
    "        PAD_SIZE = 40  # Each size\n",
    "    IMG_SIZE = TRUE_SIZE - round(PAD_SIZE*2)\n",
    "        \n",
    "    imgsuffix = 'png'\n",
    "    im_all = cv2.imread(imgpath + imgname + '.' + imgsuffix)\n",
    "    im_all = im_all[round(im_all.shape[0]/2)-300:round(im_all.shape[0]/2)+300, \n",
    "                    round(im_all.shape[1]/2)-300:round(im_all.shape[1]/2)+300, :]  # for brain_map data\n",
    "    \n",
    "    print(im_all.shape)\n",
    "\n",
    "    if im_all.shape[0] % IMG_SIZE != 0:\n",
    "        num_x = im_all.shape[0]//IMG_SIZE\n",
    "        dim_x = (num_x+1)*IMG_SIZE\n",
    "    else:\n",
    "        num_x = im_all.shape[0]//IMG_SIZE\n",
    "        dim_x = im_all.shape[0]\n",
    "    if im_all.shape[1] % IMG_SIZE != 0:\n",
    "        num_y = im_all.shape[1]//IMG_SIZE\n",
    "        dim_y = (num_y+1)*IMG_SIZE\n",
    "    else:\n",
    "        num_y = im_all.shape[1]//IMG_SIZE\n",
    "        dim_y = im_all.shape[1]\n",
    "\n",
    "    im_all_zero = np.zeros((dim_x, dim_y, im_all.shape[2]), dtype=np.uint8)\n",
    "    im_all_zero[:im_all.shape[0], :im_all.shape[1], :] = im_all\n",
    "#     im_all = im_all[:dim_x, :dim_y, :]\n",
    "    im_all = np.copy(im_all_zero)\n",
    "    im_out = np.zeros((im_all.shape[0], im_all.shape[1]))\n",
    "    im_down_out = np.copy(im_out)\n",
    "    im_all = np.pad(im_all, ((PAD_SIZE, PAD_SIZE), (PAD_SIZE, PAD_SIZE), (0,0)), 'constant')  # zero pad 20x20 along axis 0 and 1\n",
    "    \n",
    "#     fig = plt.figure(figsize=(100, 100))\n",
    "#     plt.imshow(im_all[:, :, 1])\n",
    "#     plt.show()\n",
    "\n",
    "    lin_x = np.arange(round(TRUE_SIZE/2), im_all.shape[1], IMG_SIZE)\n",
    "    lin_y = np.arange(round(TRUE_SIZE/2), im_all.shape[0], IMG_SIZE)\n",
    "    total_count = len(lin_x)*len(lin_y)\n",
    "    print(total_count)\n",
    "    \n",
    "    count = 1\n",
    "    for i in lin_x:\n",
    "        for j in lin_y:\n",
    "            print(count)\n",
    "#             if count != 4:\n",
    "#                 count += 1\n",
    "#                 continue\n",
    "            im_temp = im_all[j-round(TRUE_SIZE/2):j+round(TRUE_SIZE/2), i-round(TRUE_SIZE/2):i+round(TRUE_SIZE/2), :]\n",
    "            im, im_gt, im_masked, im_mask, im_down, factor, _, _ = readImg(im_temp)\n",
    "            if count == 1:\n",
    "                show_output = True\n",
    "            else:\n",
    "                show_output = False\n",
    "            if count % 4 == 0 and imgname == 'brain_xiaoyi_12_6':\n",
    "                [sr_image, l, model, \n",
    "                 totalTrainingTimeHr, \n",
    "                 input_noise, base_model] = train_dp(im_masked, im_gt, im_mask, iter=1, \n",
    "                         noise_reg=0.07, show_output=show_output)\n",
    "            else:\n",
    "                [sr_image, l, model, \n",
    "                 totalTrainingTimeHr, \n",
    "                 input_noise, base_model] = train_dp(im_masked, im_gt, im_mask, iter=5000, \n",
    "                         noise_reg=0.07, show_output=show_output)\n",
    "            tmp = np.squeeze(sr_image)\n",
    "            im_out[j-round(TRUE_SIZE/2):j+round(TRUE_SIZE/2-PAD_SIZE*2), i-round(TRUE_SIZE/2):\n",
    "                   i+round(TRUE_SIZE/2-PAD_SIZE*2)] = tmp[PAD_SIZE:TRUE_SIZE-PAD_SIZE, PAD_SIZE:TRUE_SIZE-PAD_SIZE]\n",
    "            im_down_out[j-round(TRUE_SIZE/2):j+round(TRUE_SIZE/2-PAD_SIZE*2), i-round(TRUE_SIZE/2):\n",
    "                        i+round(TRUE_SIZE/2-PAD_SIZE*2)] = im_down[PAD_SIZE:TRUE_SIZE-PAD_SIZE, PAD_SIZE:TRUE_SIZE-PAD_SIZE]\n",
    "            count += 1\n",
    "            \n",
    "#             if count == 5 and SAVE_OUTPUT:\n",
    "#                 cv2.imwrite(imgpath + '/output/' + imgname + '_dip_out_batch.png', norm_uint8(im_out))\n",
    "#             if count == 9 and SAVE_OUTPUT:\n",
    "#                 cv2.imwrite(imgpath + '/output/' + imgname + '_dip_out_batch.png', norm_uint8(im_out))\n",
    "            \n",
    "            if SAVE_OUTPUT:\n",
    "                cv2.imwrite(imgpath + '/output/' + imgname + str(i) + str(j) + '.png', tmp)  \n",
    "                model.save_weights(imgpath + '/output/' + imgname + str(i) + str(j))\n",
    "                base_model.save_weights(imgpath + '/output/' + imgname + str(i) + str(j) + '_base', save_format='h5')\n",
    "                sio.savemat(imgpath + '/output/' + imgname + '_inputNoise' + str(i) + str(j) + \".mat\", \n",
    "                            dict([('inputNoise', np.squeeze(input_noise))]))\n",
    "#                 inputNoise = np.squeeze(input_noise)\n",
    "#                 inputNoise = inputNoise.reshape((inputNoise.shape[0], inputNoise.shape[1]*inputNoise.shape[2]))\n",
    "#                 np.savetxt(imgpath + '/output/output_brain_xiaoyi/' + imgname + '_inputNoise' + str(i) + str(j) + '.txt', \n",
    "#                            np.asarray(np.squeeze(inputNoise)))\n",
    "    \n",
    "    for i in lin_x:\n",
    "        for j in lin_y:\n",
    "            sr_image = cv2.imread(imgpath + '/output/' + imgname + str(i) + str(j) + '.png')\n",
    "            sr_image = sr_image[:,:,0]\n",
    "            tmp = np.squeeze(sr_image)\n",
    "            im_out[j-round(TRUE_SIZE/2):j+round(TRUE_SIZE/2-PAD_SIZE*2), i-round(TRUE_SIZE/2):\n",
    "                   i+round(TRUE_SIZE/2-PAD_SIZE*2)] = tmp[PAD_SIZE:TRUE_SIZE-PAD_SIZE, PAD_SIZE:TRUE_SIZE-PAD_SIZE]\n",
    "            im_down_out[j-round(TRUE_SIZE/2):j+round(TRUE_SIZE/2-PAD_SIZE*2), i-round(TRUE_SIZE/2):\n",
    "                        i+round(TRUE_SIZE/2-PAD_SIZE*2)] = im_down[PAD_SIZE:TRUE_SIZE-PAD_SIZE, PAD_SIZE:TRUE_SIZE-PAD_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if WHOLEIMG_MODE:\n",
    "    im_out_ts = norm_uint8(im_out)\n",
    "    print(im_out_ts.shape)\n",
    "    im_mask_ts = norm_uint8(im_all[PAD_SIZE:-PAD_SIZE, PAD_SIZE:-PAD_SIZE, 0]*255)\n",
    "    print(im_mask_ts.shape)\n",
    "    im_gt_ts = norm_uint8(im_all[PAD_SIZE:-PAD_SIZE, PAD_SIZE:-PAD_SIZE, 2])\n",
    "    im_ts = np.dstack((im_mask_ts, im_out_ts, im_gt_ts))\n",
    "    im_ts = im_ts[:-60, :-60, :]\n",
    "    plt.imshow(im_ts)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WHOLEIMG_MODE and SAVE_OUTPUT:\n",
    "    cv2.imwrite(imgpath + '/output/' + imgname + '_dip_out_batch.png', im_ts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current count: 1\n",
      "190307_brain 1_Image0_index0_5-10.png\n",
      "WARNING:tensorflow:From C:\\Users\\PI-Lab\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Current count: 1\n",
      "20190411_EpiInj_thinnedskull 2_Image0_index0_5-10.png\n",
      "WARNING:tensorflow:From C:\\Users\\PI-Lab\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Session cleared.\n",
      "Current count: 2\n",
      "20190412_EpiInj_thinnedskull 3_Image0_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 3\n",
      "20190412_EpiInj_thinnedskull2 3_Image0_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 4\n",
      "20190423_thinnedskull_Epi 11_Image7_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 5\n",
      "20190425_thinnedskull_Epi 19_Image11_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 7\n",
      "20190529_findfocus  24_Image0_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 8\n",
      "20190529_findfocus  24_Image12_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 10\n",
      "532_OR_39_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 11\n",
      "532_OR_39_index0_5-10_noiseRegvsSSIM.txt\n",
      "Current count: 11\n",
      "532_OR_40_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 12\n",
      "532_OR_542_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 14\n",
      "532_OR_57_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 15\n",
      "532_OR_59_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 16\n",
      "532_OR_63_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 17\n",
      "532_OR_64_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 18\n",
      "532_OR_71_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 19\n",
      "532_OR_82_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 20\n",
      "deep_learning.zip\n",
      "Current count: 20\n",
      "input_imgs.zip\n",
      "Current count: 20\n",
      "reslt_OR_1 (14)_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 21\n",
      "reslt_OR_1 (16)_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 22\n",
      "reslt_OR_1 (2)_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 24\n",
      "reslt_OR_1 (4)_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 25\n",
      "reslt_OR_2 (20)_index0_5-10.png\n",
      "Session cleared.\n",
      "Current count: 26\n",
      "reslt_OR_2 (23)_index0_5-10.png\n"
     ]
    }
   ],
   "source": [
    "# For examining noise regularization\n",
    "if BATCH_MODE:\n",
    "    if SSIM_ITER:\n",
    "        output_folder = '/output_ssimiter/'\n",
    "    else:\n",
    "        output_folder = '/output/'\n",
    "    count = 1\n",
    "    for f in list_file:        \n",
    "        if count not in batch_range:\n",
    "            count = count + 1\n",
    "            continue\n",
    "            \n",
    "        print('Current count: ' + str(count))\n",
    "        print(f)\n",
    "        \n",
    "        imgname, imgsuffix = f.split('.')\n",
    "        if imgsuffix != 'png':\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            im = cv2.imread(imgpath + imgname + '.' + imgsuffix)\n",
    "            im = im[round(im.shape[0]/2)-150:round(im.shape[0]/2)+150, \n",
    "                    round(im.shape[1]/2)-150:round(im.shape[1]/2)+150, :]\n",
    "            im, im_gt, im_masked, im_mask, im_down, factor, _, _ = readImg(im)\n",
    "            if SSIM_ITER:\n",
    "                [sr_image, l, model, totalTrainingTimeHr, \n",
    "                 input_noise, base_model] = train_dp(im_masked, im_gt, im_mask, \n",
    "                                         iter=5000, noise_reg=0.07, \n",
    "                                         save_imglog=True,img_path=imgpath+output_folder+imgname)        \n",
    "            else:\n",
    "                [sr_image, l, model, totalTrainingTimeHr, \n",
    "                 input_noise, base_model] = train_dp(im_masked, im_gt, im_mask, \n",
    "                                         iter=5000, noise_reg=0.07, \n",
    "                                         show_output=False)\n",
    "            sr_image = np.squeeze(sr_image)\n",
    "            im_out = np.dstack((im_mask, sr_image, im_gt))\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "        \n",
    "        if SAVE_MODEL:\n",
    "            model.save(imgpath + output_folder + imgname + '.h5')\n",
    "            inputNoise = np.squeeze(input_noise)\n",
    "            inputNoise = inputNoise.reshape((inputNoise.shape[0], \n",
    "                                             inputNoise.shape[1]*inputNoise.shape[2]))\n",
    "            np.savetxt(imgpath + output_folder + imgname + '_inputNoise.txt', \n",
    "                       np.asarray(np.squeeze(inputNoise)))\n",
    "        if SAVE_OUTPUT:\n",
    "            cv2.imwrite(imgpath + output_folder + imgname + '_dip_out.png', im_out)\n",
    "            np.savetxt(imgpath + output_folder + imgname + '_Aux.txt', \n",
    "                       np.asarray([totalTrainingTimeHr]))\n",
    "            base_model.save_weights(imgpath + output_folder + imgname + '_base')\n",
    "            \n",
    "        if SAVE_LOSS:\n",
    "            np.savetxt(imgpath + output_folder + imgname + '_loss.txt', \n",
    "                       np.asarray(l))\n",
    "#         ssim_rec = np.concatenate((ssim_rec, [[ii, cur_ssim]]), axis=0)\n",
    "        \n",
    "        if count in batch_range:\n",
    "#             del model\n",
    "            K.clear_session()\n",
    "#             cuda.select_device(0)\n",
    "#             cuda.close()\n",
    "            print('Session cleared.')\n",
    "        elif count == batch_range[-1]:\n",
    "            break\n",
    "            \n",
    "        count += 1\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_msef = np.loadtxt('./Data/8_14/output_ssimiter/20190425_thinnedskull_Epi 19_Image11_index0_14-8_SSIMIter.txt') \n",
    "plt.plot(l_msef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_msef.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
